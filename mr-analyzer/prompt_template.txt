The following is the documentation in the repo where the MRs are opened. Use the info below to gain a good understanding of the MR.

--- start documentation -- here's your context ---
# Dataverse Platform Configuration Repository

## Overview

This repository serves as the central location for all declarative configuration related to data products on the Dataverse platform. It is currently in its early stages and does not have any automation tied to it yet. However, it will soon become the primary source of truth for configuring and managing data products within the Dataverse ecosystem.

## Structure

The repository is organized into several key directories:

1. `dataproducts`: Contains configurations for various data products, categorized by type (source, aggregate, platform).
2. `serviceaccounts`: Holds service account configurations for different environments (dev, preprod, prod, sandbox).

## Data Products

Data products are organized into three main categories:

- Source
- Aggregate
- Platform

Each data product typically includes:

- A `README.md` file with team information and specific details
- A `developers.yaml` file listing team members and their roles
- A `product.yaml` file defining the data product's configuration
- Environment-specific directories (dev, sandbox, etc.) with additional configurations

For example, the structure of a data product might look like this:

```
dataproducts/
└── source/
    └── marketo/
        ├── README.md
        ├── developers.yaml
        └── sandbox/
            └── product.yaml
```


## Data Product Naming Conventions

- Use lowercase all one word
- No special characters

When naming data products, especially aggregate data products, several factors should be considered:

1. **Scope and Purpose**: The name should reflect the overall scope and purpose of the data product. For example, if the data product covers multiple aspects of partner data, a more general name like "partnerbookings" might be more appropriate than a specific usecase of partnerbookings like "partnercompensation".

2. **Team Ownership**: Consider which team or group of people will be primarily working on and maintaining the data product. If the same team will be handling multiple related data sets, it may make sense to group these under a single data product.

3. **Access Patterns**: Think about who will need access to the data and whether access patterns will be similar across different components of the data product. If access needs are consistent, it supports grouping related data under one product name.

4. **Data Sources**: While aggregate data products can pull from multiple sources, consider whether the sources are closely related or diverse. Very diverse sources might indicate a need for separate data products.

5. **Future Expansion**: Choose a name that allows for future expansion of the data product's scope without becoming misleading. For instance, "partnerbookings" allows for inclusion of all partner bookings related data, training, and other partner bookings data.

6. **Consistency with Existing Products**: Ensure the naming aligns with other existing data products in the dataverse ecosystem for consistency.

7. **Clarity and Brevity**: The name should be clear and descriptive, but also concise. Avoid overly long or complex names.

8. **Avoid Overly Specific Names**: Unless the data product is truly limited in scope, avoid names that are too specific to a single use case or data type.

Remember that while the data product name is important, the internal structure (such as schema and table names) can provide more specific organization within the data product. The data product name should provide a clear, high-level understanding of the data's domain and purpose.

### For Source aligned data products

- The LDAP group name should follow the format `dataverse-source-[data_product_name]`. For example, for the `Customer360` system, the corresponding LDAP group would be `dataverse-source-mdmparty`. While the application name is `Customer360`, the LDAP group name should be `mdmparty` as that is the data product name and how it is referred to in normal conversation.

## Service Accounts

Service account configurations are organized by environment:

```
serviceaccounts/
├── dev/
├── preprod/
├── prod/
└── sandbox/
```

Each environment directory contains YAML files defining service accounts for various purposes, such as Fivetran integration, DBT deployment, and platform operations.

## Creating Service Account for Snowflake DB

To enable seamless integration with external systems like Astro and Atlan, you need to create a service account for accessing the Snowflake database. Each product requires a dedicated service account that is specific to both the product and its environment, ensuring secure and efficient access management.

To create a service account:

Create a file in this repository, with the naming convention mentioned below, and located in this directory *dataproduct-config/serviceaccounts/<env>* inside an environment specific folder.

  **File name:** <product_name>_<tool_name>_<env>_appuser.yaml

  **Service account name:** <product_name>_<tool_name>_<env>_appuser
```
name: marketo_astro_dev_appuser
comment: "service account in rhdev for astro for marketo"
email: <marketo_dev_team_email>@redhat.com>
```
For more details, refer to the [MR](https://gitlab.cee.redhat.com/dataverse/dataverse-config/dataproduct-config/-/merge_requests/126)

## Executing SQL Statement

As part of the development process for any product, you need to execute various SQL statements, such as DDL or DML, either on an ad-hoc basis or in a repetitive manner based on the requirements. The following details outline the steps to execute these statements effectively.

1.Fork the dataproduct config repository, clone it, and create a feature branch.

```
git clone git@gitlab.cee.redhat.com:<username>/dataproduct-config.git
cd dataproduct-config
git checkout -b <feature-branch-name>
```
2.Go to your product and environment:

```
Eg:
 dataproduct-config/dataproducts/source/ciam/sandbox/
```
3.Create a folder migrations, if it does not exists in the environment where you want to run .sql files.

```
Eg:
dataproduct-config/dataproducts/source/ciam/sandbox/migrations/
```
4.Create the .sql file with the below naming convention under migrations.

<version_no>__<type_of_statement>.sql

Example repo: [mdmproduct](https://gitlab.cee.redhat.com/dataverse/dataverse-config/dataproduct-config/-/tree/main/dataproducts/source/mdmproduct/dev/migrations)

In case if you want to execute the .sql file in a repetitive manner, then you must use R instead of V in the beginning of the file name. If not, you must use V as a version.

Eg: R__sp_add_sales.sql

5.Raise an MR.

For more details, refer the sample [MR](https://gitlab.cee.redhat.com/dataverse/dataverse-config/dataproduct-config/-/merge_requests/131)
Additional details

For the schema change details, refer this [readme](https://github.com/Snowflake-Labs/schemachange).


## Setting up consumer group for dataproduct

If you want to set up consumer group for providing access to users who are not part of any dataproduct, you have to create new rover group 
for the respective part. Syntax for consumer group name is `dataverse-consumer-<<dataproduct-name>>-<<mart-name>>` and `mart-name` should be
provided without any `_`

E.g. For mart `marts` in costops dataproduct will have rover group `dataverse-consumer-costops-marts` and for mart `test_marts`, rover 
group will be `dataverse-consumer-costops-testmarts`

Once the rover group setup is done, update the product.yaml with rover group mentioned as consumer for the mart like
```yaml
data_product_db:
- database: fivetranplatform_db
  presentation_schemas:
  - name: fivetrancostops_marts
    consumers:
    - kind: consumer_group
      name: dataverse-consumer-fivetranplatform-fivetrancostopsmarts
```

Also add consumers.yaml under `dataproducts/<<dataproduct-type>>/<<data-product>>` mentioning the list of consumer groups like

```yaml
consumer_groups:
- dataverse-consumer-fivetranplatform-fivetrancostopsmarts
```

This will start syncing rover group members in snowflake and will provide SR role to the rover group members on that particular environment. 

## Specifying the consumers for a dataproduct

Dataproduct want to share the model generated by them to other dataproduct or serviceaccount, this can be achieved by specifying the
consumers for a mart/schema.

1. Navigate to the `dataproducts/<<dataproduct-type>>/<<data-product>>/<<env>>` in the repository.
2. Open the product.yaml and specify the respective consumer like

```yaml
data_product_db:
- database: fivetranplatform_db
  presentation_schemas:
  - name: fivetrancostops_marts
    consumers:
    - name: costops
      kind: data_product
    - name: costops_ui_sandbox_appuser
      kind: service_account
```

3. Send an MR with the changes and request dataproduct team approvers to validate the MR.

Note: DataProduct or ServiceAccount getting mentioned should exist before or should be created in the MR.

## Manage snowpipe resources' configurations

1. Navigate to the `dataproducts/source/<<dataproduct>>/<<env>>` in this repository
2. Within your dataproduct sub directory, create a new file snowpipeconfig.yaml
3. Using the following example, customize the file as needed:
    ```
    ---
    dataproduct: marketo
    internal_stages:
      - name: MARKETO_INT_DEMO_STAGE
        encryption:
          type: SNOWFLAKE_SSE
        directory:
          enable: true
        file_format: CSV
        tag:
          "marketo": "init_data"
    ```

Note: only Named internal stages are supported at the moment. As the feature evolves, this document will be updated to reflect new configurations and guidelines for managing snowpipe resources' on the Dataverse platform.



This is what we got from the MR : 

**Merge Request Details:**
- Title: {mr_title}
- Description: {mr_description}
- Source Branch: {source_branch}
- Target Branch: {target_branch}
- Commit: {commit_sha}

**Diff Content:**
```diff
{diff_content}
```

Mandatory sections. Please provide a summary that includes the following sections. Skip the optional sections from the final output:

---
## Overview
Brief description of what this MR accomplishes. DO NOT be influenced by the MR title or description. Focus on the actual changes in the diff. Ignore .gitkeep additions.
Ignore .gitkeep changes.    
---
## Key Changes
List the main changes made. It is illegal to promote to multiple environments by adding multiple product.yaml files across dev/pre-prod/prod directories. Call it out when you see it. Ignore .gitkeep additions.
- Use bullet points for clarity. Do not include promotion checklist items here since there's a separate section for that. NO need to mention changes in markdown files.
Ignore .gitkeep additions.
---
## Files Modified
Summary of which files/areas were changed. **DO NOT LIST** .gitkeep additions. Use bullet points only.

---
## Promotion Checklist (Conditional Generation)
**GENERATE THE "PROMOTION CHECKLIST" SECTION ONLY IF** this is a promotion MR to pre-prod or prod **AND** there are items to summarize in the checklist.
**IF GENERATING THIS SECTION**:
Summarize the promotion checklist as extensive bullet points, especially items that were not completed. Also summarize in moderate detail all the information related to the completed items. Any code/SQL in the promotion checklist should be summarized appropriately; they should not necessarily be included as code changes if not present in other sections.
**OTHERWISE (if not a promotion MR, or if all checklist items were completed and there's nothing specific to call out for review): GENERATE ABSOLUTELY NOTHING FOR THE "PROMOTION CHECKLIST" SECTION. DO NOT OUTPUT ANY TEXT EXPLAINING ITS ABSENCE.**

Format the response in clear markdown with appropriate headers and bullet points.
Keep the summary concise but comprehensive - aim for 200-300 words total. Ensure paragraphs are correctly indented.